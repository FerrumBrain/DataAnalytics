{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Introduction",
   "id": "ea7c28b8814aa726"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For our project we are analyzing the dataset of all flights that departed from the three main New York City airports in 2023. For this project we will be analyzing all the features of the dataset and from the auxiliary ones. Our target variable for regression is 'arr_delay' and for classification we have chosen cancellation prediction. When we don't have information about departure or arrival time it means that the flight was cancelled.",
   "id": "63023d4193756cb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Cleaning",
   "id": "83ff8b942ba851a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Overview of datasets:\n",
    "* airlines.csv\n",
    "    * `carrier` -- Two-letter airline code.\n",
    "    * `name` -- Full name of the airline.\n",
    "\n",
    "* airports.csv\n",
    "    * `faa` -- FAA code of the airport (e.g., JFK for John F. Kennedy).\n",
    "    * `name` -- Name of the airport.\n",
    "    * `lat` -- Latitude of the airport (decimal format).\n",
    "    * `lon` -- Longitude of the airport (decimal format).\n",
    "    * `alt` -- Altitude of the airport in feet.\n",
    "    * `tz` -- Time zone offset (UTC offset). Can be `null`\n",
    "    * `dst` -- Daylight saving time indicator (`A` = Active, etc.). Can be `null` but it is `null` iff `tz` is `null`\n",
    "    * `tzone` -- IANA time zone name (e.g., America/New_York). Can be `null` but it is `null` in superset of cases when `tz` is null, therefore can be filled sometimes with already existing values\n",
    "\n",
    "* flights.csv\n",
    "    * `year` -- Year of the flight. Always `2023`, therefore dropped\n",
    "    * `month` -- Month of the flight.\n",
    "    * `day` -- Day of the flight.\n",
    "    * `dep_time` -- Actual departure time (local, in military format). Can be `null`\n",
    "    * `sched_dep_time` -- Scheduled departure time (local, in military format).\n",
    "    * `dep_delay` -- Departure delay in minutes (negative if early). Can be `null` iff `dep_time` is null\n",
    "    * `arr_time` -- Actual arrival time (local, in military format). Can be `null` in superset of cases when `dep_delay` is `null`. If it is `null` we assume that flight was cancelled.\n",
    "    * `sched_arr_time` -- Scheduled arrival time (local, in military format).\n",
    "    * `arr_delay` -- Arrival delay in minutes (negative if early). Can be `null` in superset of cases when `arr_time` is `null`. Can be filled in as difference between `sched_arr_time` and `arr_time`\n",
    "    * `carrier` -- Two-letter airline code (links to `airlines.csv`).\n",
    "    * `flight` -- Flight number.\n",
    "    * `tailnum` -- Aircraft tail number (links to `planes.csv`). Cna be `null` but number is small => can be dropped.\n",
    "    * `origin` -- Origin airport code (links to `airports.csv`).\n",
    "    * `dest` -- Destination airport code (links to `airports.csv`).\n",
    "    * `air_time` -- Total air time in minutes. Can be `null` iff `arr_delay` is null but we decided not to use this column => can be ignored.\n",
    "    * `distance` -- Distance of the flight in miles.\n",
    "    * `hour` -- Scheduled departure hour (derived from `sched_dep_time`).\n",
    "    * `minute` -- Scheduled departure minute (derived from `sched_dep_time`).\n",
    "    * `time_hour` -- Rounded time to the nearest hour (useful for joining with weather data).\n",
    "\n",
    "* planes.csv\n",
    "    * `tailnum` -- Unique aircraft identifier (matches with `flights.tailnum`).\n",
    "    * `year` -- Year the plane was manufactured. Can be `null` but it is quite rare case, therefore can be dropped\n",
    "    * `type` -- Aircraft type (e.g., \"Fixed wing multi engine\").\n",
    "    * `manufacturer` -- Manufacturer of the aircraft (e.g., Boeing, Airbus).\n",
    "    * `model` -- Model of the aircraft (e.g., \"A320\").\n",
    "    * `engines` -- Number of engines on the aircraft.\n",
    "    * `seats` -- Number of passenger seats on the plane. Always `0`, therefore dropped\n",
    "    * `speed` -- Typical cruise speed (if available; may be NaN).\n",
    "    * `engine` -- Type of engine (e.g., \"Turbo-fan\").\n",
    "\n",
    "* weather.csv\n",
    "    * `origin` -- Airport code where the weather data is recorded (links to `airports.faa`).\n",
    "    * `year` -- Year of the weather record.\n",
    "    * `month` -- Month of the weather record.\n",
    "    * `day` -- Day of the weather record.\n",
    "    * `hour` -- Hour of the weather observation (local).\n",
    "    * `temp` -- Temperature in degrees Fahrenheit. Can be `null` in superset of cases when `precip` is `null`\n",
    "    * `dewp` -- Dewpoint temperature in degrees Fahrenheit. Can be `null` iff `temp` is `null`\n",
    "    * `humid` -- Relative humidity (%). Can be `null` iff `temp` is `null`\n",
    "    * `wind_dir` -- Wind direction in degrees (0° = North, 90° = East, etc.).\n",
    "    * `wind_speed` -- Wind speed in mph.\n",
    "    * `wind_gust` -- Wind gust speed in mph (if available).\n",
    "    * `precip` -- Precipitation in inches. Can be `null`.\n",
    "    * `pressure` -- Atmospheric pressure in millibars (if available). Can be `null` in superset of cases when `temp` is `null`\n",
    "    * `visib` -- Visibility in miles.\n",
    "    * `time_hour` -- Time of the observation rounded to the nearest hour (links to `flights.time_hour`).\n",
    "\n"
   ],
   "id": "9a0188dceeba2cc2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "59d90b0d1b02590c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "!pip install -r requirements.txt"
   ],
   "id": "245205517da0c3b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load datasets",
   "id": "a4d742d68e195183"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_csv(filename):\n",
    "    df = pd.read_csv(\n",
    "        filename,\n",
    "        header=0,                     # Use the first row as the header\n",
    "        delimiter=';',                # Use semicolon as the main delimiter\n",
    "        decimal=',',                  # Specify that commas are used as decimals\n",
    "        quotechar='\"',                # Handle quotes around strings\n",
    "        skipinitialspace=True,        # Skip spaces after delimiters\n",
    "    )\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "airlines = read_csv('airlines.csv')\n",
    "airports = read_csv('airports.csv')\n",
    "planes = read_csv('planes.csv')\n",
    "flights = read_csv('flights.csv')\n",
    "weather = read_csv('weather.csv')"
   ],
   "id": "f7daf9dd451fd171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "planes['year'] = planes['year'].astype('Int64')\n",
    "flights['dep_time'] = flights['dep_time'].astype('Int64')\n",
    "flights['dep_delay'] = flights['dep_delay'].astype('Int64')\n",
    "flights['arr_time'] = flights['arr_time'].astype('Int64')\n",
    "flights['arr_delay'] = flights['arr_delay'].astype('Int64')"
   ],
   "id": "dea66fd03b2dd94b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def check_for_nulls(df):\n",
    "    res = {}\n",
    "    for c in df.columns:\n",
    "        if df[df[c].isnull()].shape[0] != 0:\n",
    "            res[c] = df[df[c].isnull()].shape[0]\n",
    "    return res"
   ],
   "id": "572ecf65add28033",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Nullable columns in airlines:\", check_for_nulls(airlines))\n",
    "print(\"Nullable columns in airports:\", check_for_nulls(airports))\n",
    "print(\"Nullable columns in planes:\", check_for_nulls(planes))\n",
    "print(\"Nullable columns in flights:\", check_for_nulls(flights))\n",
    "print(\"Nullable columns in weather:\", check_for_nulls(weather))"
   ],
   "id": "db41668d83fcfcd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clean Datasets",
   "id": "2a84846bea4a0912"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clear_airports(df): # fill `tzone` if it can be filled, drop otherwise. If `tz` is unknown, drop\n",
    "    df = df.dropna(subset=['tz', 'dst'])\n",
    "\n",
    "    for idx, row in df[df['tzone'].isnull()].iterrows():\n",
    "        matching_row = df[(df['tz'] == row['tz']) & pd.notnull(df['tzone'])]\n",
    "        if not matching_row.empty:\n",
    "            df.at[idx, 'tzone'] = matching_row['tzone'].iloc[0]\n",
    "        else:\n",
    "            df = df.drop(idx)\n",
    "    return df"
   ],
   "id": "6503774e1ae900a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clear_planes(df): # drop all planes if `year` is unknown\n",
    "    return df.dropna()"
   ],
   "id": "cbf90cdd8af4e9a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clear_flights(df): # drop if `tailnum` is unknown, fix military format of time, fill air_time where needed\n",
    "    df = df.dropna(subset=['tailnum'])\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        df.at[idx, 'dep_time'] = df.at[idx, 'dep_time'] % 100 + (df.at[idx, 'dep_time'] // 100) * 60\n",
    "        df.at[idx, 'arr_time'] = df.at[idx, 'arr_time'] % 100 + (df.at[idx, 'arr_time'] // 100) * 60\n",
    "        df.at[idx, 'sched_dep_time'] = df.at[idx, 'sched_dep_time'] % 100 + (df.at[idx, 'sched_dep_time'] // 100) * 60\n",
    "        df.at[idx, 'sched_arr_time'] = df.at[idx, 'sched_arr_time'] % 100 + (df.at[idx, 'sched_arr_time'] // 100) * 60\n",
    "\n",
    "    for idx, row in df[df['air_time'].isnull()].iterrows():\n",
    "        df.at[idx, 'arr_delay'] = df['arr_time'].iloc[0] - df['sched_arr_time'].iloc[0]\n",
    "        df.at[idx, 'air_time'] = df['arr_time'].iloc[0] - df['dep_time'].iloc[0]\n",
    "    return df"
   ],
   "id": "d6aa14e4183997ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clear_weather(df): # here we ignore all nulls and keep them as is\n",
    "    return df"
   ],
   "id": "11ef0e48bd74cbcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clean_airlines = airlines\n",
    "clean_airports = clear_airports(airports.copy())\n",
    "clean_planes = clear_planes(planes.copy())\n",
    "clean_flights = clear_flights(flights.copy())\n",
    "clean_weather = clear_weather(weather.copy())"
   ],
   "id": "d7dc7662a2607d7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Nullable columns in airlines:\", check_for_nulls(clean_airlines))\n",
    "print(\"Nullable columns in airports:\", check_for_nulls(clean_airports))\n",
    "print(\"Nullable columns in planes:\", check_for_nulls(clean_planes))\n",
    "print(\"Nullable columns in flights:\", check_for_nulls(clean_flights))\n",
    "print(\"Nullable columns in weather:\", check_for_nulls(clean_weather))"
   ],
   "id": "fe68afa6e555868f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Airports old vs new:\", airports.shape, clean_airports.shape)\n",
    "print(\"Planes old vs new:\", planes.shape, clean_planes.shape)\n",
    "print(\"Flights old vs new:\", flights.shape, clean_flights.shape)\n",
    "print(\"Weather old vs new:\", weather.shape, clean_weather.shape)"
   ],
   "id": "8a0be35aae2bf8e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merge datasets",
   "id": "799dc72b271513c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# merge flights with info about origin airport\n",
    "flights_with_origin_info = pd.merge(\n",
    "    clean_flights,\n",
    "    clean_airports,\n",
    "    how='left',\n",
    "    left_on='origin',\n",
    "    right_on='faa',\n",
    "    suffixes=('', '_origin')\n",
    ")\n",
    "\n",
    "# merge obtained dataset with info about destination airport\n",
    "flights_with_origin_and_dest = pd.merge(\n",
    "    flights_with_origin_info,\n",
    "    clean_airports,\n",
    "    how='inner',\n",
    "    left_on='dest',\n",
    "    right_on='faa',\n",
    "    suffixes=('_origin', '_dest')\n",
    ")\n",
    "\n",
    "# merge obtained dataset with info about plane\n",
    "flights_with_origin_dest_and_planes = pd.merge(\n",
    "    flights_with_origin_and_dest,\n",
    "    clean_planes,\n",
    "    how='left',\n",
    "    left_on=['tailnum'],\n",
    "    right_on=['tailnum'],\n",
    "    suffixes=('', '_plane')\n",
    ")\n",
    "\n",
    "# merge obtained dataset with info about weather at the departure time\n",
    "merged_df = pd.merge(\n",
    "    flights_with_origin_dest_and_planes,\n",
    "    clean_weather,\n",
    "    how='left',\n",
    "    left_on=['origin', 'year', 'month', 'day', 'hour'],\n",
    "    right_on=['origin', 'year', 'month', 'day', 'hour'],\n",
    "    suffixes=('', '_weather')\n",
    ")"
   ],
   "id": "7fabd03cdb08cb7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# drop columns that are not needed for classification and regression\n",
    "merged_df = merged_df.drop(['arr_time', 'flight', 'tailnum', 'air_time', 'time_hour', 'faa_origin', 'name_origin', 'lat_origin', 'lon_origin', 'alt_origin', 'tz_origin', 'dst_origin', 'tzone_origin', 'faa_dest', 'name_dest', 'dst_dest', 'tzone_dest', 'time_hour_weather', 'year', 'speed'], axis=1)\n",
    "\n",
    "merged_df['is_cancelled'] = merged_df['arr_delay'].isnull()\n"
   ],
   "id": "3d157de73fe76ebf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged_df.to_csv(\"merged_df.csv\", index=False)",
   "id": "4ea28fd2a95718c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split into 3 datasets depending on origin airport\n",
    "ewr_df = merged_df[merged_df['origin'] == 'EWR'].drop('origin', axis=1)\n",
    "jfk_df = merged_df[merged_df['origin'] == 'JFK'].drop('origin', axis=1)\n",
    "lga_df = merged_df[merged_df['origin'] == 'LGA'].drop('origin', axis=1)"
   ],
   "id": "aeb46aa7c1f7656e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# process each dataset and create datasets for both classification and regression task\n",
    "ewr_delay_df = ewr_df.drop('is_cancelled', axis=1).dropna(subset=['arr_delay'])\n",
    "ewr_cancel_df = ewr_df.drop(['dep_delay', 'arr_delay'], axis=1)\n",
    "jfk_delay_df = jfk_df.drop('is_cancelled', axis=1).dropna(subset=['arr_delay'])\n",
    "jfk_cancel_df = jfk_df.drop(['dep_delay', 'arr_delay'], axis=1)\n",
    "lga_delay_df = lga_df.drop('is_cancelled', axis=1).dropna(subset=['arr_delay'])\n",
    "lga_cancel_df = lga_df.drop(['dep_delay', 'arr_delay'], axis=1)"
   ],
   "id": "380811211f698694",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ewr_delay_df.to_csv(\"ewr_delay.csv\", index=False)\n",
    "jfk_delay_df.to_csv(\"jfk_delay.csv\", index=False)\n",
    "lga_delay_df.to_csv(\"lga_delay.csv\", index=False)\n",
    "ewr_cancel_df.to_csv(\"ewr_cancel.csv\", index=False)\n",
    "jfk_cancel_df.to_csv(\"jfk_cancel.csv\", index=False)\n",
    "lga_cancel_df.to_csv(\"lga_cancel.csv\", index=False)"
   ],
   "id": "9aaa51d99489c5f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exporatory Data Analysis",
   "id": "787a7a58d19b772c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First, let's take a general look over the data distribution. To start with, how many flights are done each month and how delayed flights are distributed over them.",
   "id": "d8fc0c0f98bba334"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import seaborn as sns",
   "id": "68e6358275e6c652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "monthly_delays = merged_df.groupby('month').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_delays.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Number of Flights per Month', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Number of Delayed Flights', fontsize=12)\n",
    "plt.xticks(ticks=range(12), labels=[f'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "805b2ced2e92aca6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flights_delayed = merged_df[(merged_df['arr_delay'] > 15) | (merged_df['dep_delay'] > 15)]\n",
    "\n",
    "monthly_delays = flights_delayed.groupby('month').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_delays.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Number of Flights Delayed > 15 Minutes per Month', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Number of Delayed Flights', fontsize=12)\n",
    "plt.xticks(ticks=range(12), labels=[f'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "157d0c94e5e22699",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "From the plot above we may try to derive some conclusions:\n",
    "- It is clear that the most delays occur in the peak summer months June and July, which may be due to overall increased air traffic, congestions of airports and weather conditions\n",
    "- Similarly, autumn months, when the travels are less frequent, are less affected by delays\n",
    "\n",
    "To analyse this further, we can try to look into differences between arr_delay and dep_delay:"
   ],
   "id": "f4815dc5c9463e5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flights_delayed = merged_df[(merged_df['dep_delay'] > 15)]\n",
    "\n",
    "monthly_delays = flights_delayed.groupby('month').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_delays.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Number of Flights Departed > 15 Minutes than expected per Month', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Number of Delayed Flights', fontsize=12)\n",
    "plt.xticks(ticks=range(12), labels=[f'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fae91db4c6822aee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flights_delayed = merged_df[(merged_df['arr_delay'] > 15)]\n",
    "\n",
    "monthly_delays = flights_delayed.groupby('month').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_delays.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Number of Flights Arrived > 15 Minutes than expected per Month', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Number of Delayed Flights', fontsize=12)\n",
    "plt.xticks(ticks=range(12), labels=[f'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e75ddf9f88d45cba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The plots show that in some months there is a tendency in delayed departures, but not at the identified peak months. Let's see how delayed arrivals are distributed over the source airports:",
   "id": "14eaf359f069a5f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flights_delayed = merged_df[(merged_df['arr_delay'] > 15) | (merged_df['dep_delay'] > 15)]\n",
    "\n",
    "delays_by_destination = flights_delayed.groupby('origin').size().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "delays_by_destination.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Number of Delayed Flights (> 15 Minutes) by Origin Airport', fontsize=16)\n",
    "plt.xlabel('Destination Airport', fontsize=12)\n",
    "plt.ylabel('Number of Delayed Flights', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "929871ff0cd56dcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And what are mean delays in them:",
   "id": "bbf084a412dee8de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "flights_delayed.groupby('origin')[['dep_delay', 'arr_delay']].mean().sort_values('arr_delay', ascending=False)",
   "id": "d5b1b715593a53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There is no significant difference between the origin airports in terms of delays, let's investigate the destination airports in the similar way:",
   "id": "c5da525903da7ffa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flights_delayed = merged_df[(merged_df['arr_delay'] > 15) | (merged_df['dep_delay'] > 15)]\n",
    "\n",
    "delays_by_destination = flights_delayed.groupby('dest').size().sort_values(ascending=False)\n",
    "delays_by_destination = delays_by_destination[delays_by_destination >= 500]\n",
    "\n",
    "# Step 3: Plot the result\n",
    "plt.figure(figsize=(14, 7))\n",
    "delays_by_destination.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Number of Delayed Flights (> 15 Minutes) by Destination Airport (>500 delays over year)', fontsize=16)\n",
    "plt.xlabel('Destination Airport', fontsize=12)\n",
    "plt.ylabel('Number of Delayed Flights', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3f369918cd1b2053",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The above plot does not contain destination airpots with less than 500 delayed flights over the year (for visual purposes). We can clearly observe a skewed distribution with several airports constituting to the most of the delays. To indicate it more formally, we can investigate cumulative percentage over Pareto threshold:",
   "id": "ed9cb8a4e16c1fbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "delays_by_destination = flights_delayed.groupby('dest').size()\n",
    "delays_by_destination = delays_by_destination[delays_by_destination >= 100].sort_values(ascending=False)\n",
    "\n",
    "cumulative_delays = delays_by_destination.cumsum()\n",
    "cumulative_percentage = 100 * cumulative_delays / cumulative_delays.iloc[-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cumulative_percentage, marker='o', color='skyblue', label='Cumulative Percentage')\n",
    "plt.axhline(y=80, color='r', linestyle='--', label='80% Threshold')\n",
    "\n",
    "plt.title('Cumulative Percentage of Delays by Destination Airport', fontsize=16)\n",
    "plt.xlabel('Destination Airport (sorted by delay frequency)', fontsize=12)\n",
    "plt.ylabel('Cumulative Percentage (%)', fontsize=12)\n",
    "plt.xticks(ticks=np.arange(len(cumulative_percentage)), labels=cumulative_percentage.index, rotation=90)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pareto_threshold = (cumulative_percentage <= 80).sum()\n",
    "print(f\"Number of destinations accounting for 80% of delays: {pareto_threshold} out of {len(delays_by_destination)}\")"
   ],
   "id": "86737852ec0bd78f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "With this, we see that around 20-30% of the airports (on the left) contribute most to the delays: after reaching 80% the curve significantly flattens. \n",
    "\n",
    "Similarly, by observing amount of flights for each hour of the day versus delayed flights we can see that evening hours contribute more to the delays:"
   ],
   "id": "39bebb5abc506040"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flights_delayed = merged_df[(merged_df['arr_delay'] > 15) | (merged_df['dep_delay'] > 15)]\n",
    "\n",
    "flights_delayed['dep_hour'] = flights_delayed['dep_time'] // 60\n",
    "\n",
    "hourly_delays = flights_delayed.groupby('dep_hour').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "hourly_delays.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Number of Flights Delayed > 15 Minutes per Hour', fontsize=14)\n",
    "plt.xlabel('Hour of the Day', fontsize=12)\n",
    "plt.ylabel('Number of Delayed Flights', fontsize=12)\n",
    "plt.xticks(ticks=range(24), labels=[f'{hour}:00' for hour in range(24)], rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "2024cbf806e7c185",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_flights = merged_df\n",
    "all_flights['dep_hour'] = all_flights['dep_time'] // 60\n",
    "\n",
    "hourly_all_delays = all_flights.groupby('dep_hour').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "hourly_all_delays.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Number of Flights Delayed > 15 Minutes per Hour', fontsize=14)\n",
    "plt.xlabel('Hour of the Day', fontsize=12)\n",
    "plt.ylabel('Number of Delayed Flights', fontsize=12)\n",
    "plt.xticks(ticks=range(24), labels=[f'{hour}:00' for hour in range(24)], rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5de16052b5c9cdbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Which can be for various reasons:\n",
    "- Operational congestion of accumulating delays and mismanagements throughout the day (thus the increasing of the amount of delays) \n",
    "- Less space for adjustments \n",
    "- Unequal staffing or external conditions like weather and decreased visibility in the evening hours\n",
    "\n",
    "The weather data for the dataset mostly lacks precise temp/humidity/etc data. We can try to observe the distribution of existing to understand whether this data can be reliably used in the future investigation:"
   ],
   "id": "10bd928d0b33d018"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "airports = [\"JFK\", \"EWR\", \"LGA\"]\n",
    "\n",
    "for airport in airports:\n",
    "    filtered_weather = clean_weather[clean_weather['origin'].eq(airport) \n",
    "                                     & clean_weather['temp'].notnull() \n",
    "                                     & clean_weather['dewp'].notnull() \n",
    "                                     & clean_weather['humid'].notnull()]\n",
    "    \n",
    "    filtered_weather['date'] = pd.to_datetime(filtered_weather[['year', 'month', 'day']])    \n",
    "    daily_counts = filtered_weather.groupby('date').size()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    daily_counts.plot(kind='line', title='Number of Weather per Day for Selected Airports')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Rows')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ],
   "id": "6dfda1f5b84f13ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It is clear that only a few dates during different periods have almost complete weather coverage in all three airports, which is not enough to rely on weather data when solving the problem. \n",
    "\n",
    "Let's observe if the delays depend on a particular carrier:"
   ],
   "id": "c9cae718c6f009bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_delays = merged_df.groupby('carrier')[['arr_delay', 'dep_delay']].mean().reset_index().sort_values(\"arr_delay\", ascending=False)\n",
    "\n",
    "# Rename columns for clarity\n",
    "mean_delays.columns = ['Carrier', 'Mean Arrival Delay (minutes)', 'Mean Departure Delay (minutes)']\n",
    "\n",
    "mean_delays"
   ],
   "id": "3342c6a49165979e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There is a clear observable dependency between carriers and delays.\n",
    "\n",
    "Finally, seeing a correlation matrix for delays can be beneficial to see if there are any more dependencies worth investigating."
   ],
   "id": "93928c801f04f5ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_df = merged_df.select_dtypes(include=np.number).corr()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(data=corr_df[['arr_delay', 'dep_delay']], annot=True, cmap='YlGnBu')\n",
    "\n",
    "plt.show()"
   ],
   "id": "361675cae9333d60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Apart from weather conditions, which we considered unreliable, there is no meaningful correlation with other variables.",
   "id": "4dce61570545da22"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
